{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8b9d94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******* Wellcome to BestShoes ********\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "import numpy\n",
    "import re\n",
    "import time\n",
    "print (\"******* Wellcome to BestShoes ********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b00af739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--->Load Html Document from www.Asos.com\n",
    "def load_soup_object(html_Doc):\n",
    "    soup_obj = BeautifulSoup(html_Doc.text ,'html.parser')\n",
    "    return soup_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23428a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractInfo_FromSite(link, respone, agent, numberCatalog , Gender, IsfirstColor):\n",
    "    Shoes_Item = load_soup_object(respone)      #BeautifulSoup\n",
    "    \n",
    "    ProductKey , Price = \"\" , 0\n",
    "    Name , Color , Commpersion , Type , Brand = \"\" , \"\" , \"\" , \"\" , \"\"\n",
    "    Reviews, GlobalRank , RankSize , RankComfort ,RankQuality = 0 ,0,0,0 ,0\n",
    "    MaterialSoleRubber , MaterialSolePolyester , MaterialSoleTextile ,MaterialSoleThermoplasticPolyurethane , MaterialSoleOther, MaterialSoleLeather= 0,0,0,0,0,0\n",
    "    MaterialUpperRubber , MaterialUpperPolyester , MaterialUpperTextile , MaterialUpperThermoplasticPolyurethane, MaterialUpperOther , MaterialUpperLeather =0, 0,0,0,0,0\n",
    "    templink = []\n",
    "    \n",
    "    \n",
    "    driver = webdriver.Chrome(\"C:\\Program Files (x86)\\Google\\chromedriver.exe\")   #->>>Seleinum\n",
    "    driver.implicitly_wait(10)\n",
    "    driver.get(link)\n",
    "    try:\n",
    "        GlobalRank_Item = WebDriverWait(driver, 30).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR,'.FPW6c .X3LJZ .I21qs')))\n",
    "    except:\n",
    "        GlobalRank_Item = []\n",
    "    Name_Item = driver.find_elements(By.CSS_SELECTOR, \"#pdp-react-critical-app .jcdpl\")\n",
    "    Price_Item = driver.find_elements(By.CSS_SELECTOR,'.MwTOW')\n",
    "    Color_Item = driver.find_elements(By.CSS_SELECTOR,'.aKxaq')\n",
    "    Rank_Item = driver.find_elements(By.CSS_SELECTOR,'.cnock .eJLtp')\n",
    "    Reviews_Item = driver.find_elements(By.CSS_SELECTOR,\".FPW6c .X3LJZ div\")\n",
    "\n",
    "    #--->Other link for other colors\n",
    "    ColorList_other_ItemLinks = driver.find_elements(By.CSS_SELECTOR,\"li .PSk4r\")\n",
    "    for x in ColorList_other_ItemLinks:\n",
    "        templink.append(x.get_attribute('href'))\n",
    "    for name in Name_Item:\n",
    "        Name = name.text\n",
    "    for color in Color_Item:\n",
    "        Color=color.text \n",
    "    for price in Price_Item:\n",
    "        if price.text.find(' ')>=0:\n",
    "            if price.text.count(' ') == 1:\n",
    "                Price=price.text[:price.text.index(' ')]\n",
    "            else:\n",
    "                Price=price.text[price.text.find(' ')+1:price.text.rindex(' ')]\n",
    "    for rank in GlobalRank_Item:\n",
    "        GlobalRank = rank.text\n",
    "    if len(Reviews_Item) != 0:\n",
    "        Reviews = Reviews_Item[3].text[1:-1]\n",
    "    i=0\n",
    "    for rank in Rank_Item:\n",
    "        style = rank.value_of_css_property('left')\n",
    "        left_value = style.replace(\"px\", \"\")\n",
    "        if i==0:\n",
    "            RankSize = left_value\n",
    "        if i ==1:\n",
    "            RankComfort = left_value\n",
    "        if i ==2:\n",
    "            RankQuality = left_value\n",
    "        i+=1\n",
    "    driver.close()\n",
    "    \n",
    "    #Using With BeaotifulSoup\n",
    "    Productkey_Item = Shoes_Item.find_all(\"p\", class_=\"Jk9Oz\") \n",
    "    Type_Item = Shoes_Item.select(\"#productDescriptionDetails .F_yfF\")\n",
    "    Brand_Item = Shoes_Item.select(\".accordion-item-module_contentWrapper__h3KoR .F_yfF a\")\n",
    "    Details_Item = Shoes_Item.select(\"#productDescriptionDetails .F_yfF li\")\n",
    "    Compersion = Shoes_Item.select(\"#productDescriptionAboutMe .accordion-item-module_content__2cDKX .F_yfF\")\n",
    "    upper, sole = \"\" , \"\"\n",
    "    for com in Compersion:\n",
    "        compersion = com.get_text().replace(' ', '') #delete space\n",
    "        if compersion.find(\"Sole:\")>= 0 and compersion.find(\"Upper:\")>= 0:\n",
    "            sole = compersion[compersion.index(\"Sole:\"):compersion.index(\"Upper:\")]\n",
    "            upper = compersion[compersion.index(\"Upper:\"):]\n",
    "        elif compersion.find(\"Sole:\")>= 0:\n",
    "            sole = compersion[compersion.index(\"Sole:\"):]\n",
    "        elif compersion.find(\"Upper:\")>= 0:\n",
    "            upper = compersion[compersion.index(\"Upper:\"):]\n",
    "        numberSole = re.findall(r'\\d+', sole)\n",
    "        numberUpper  =  re.findall(r'\\d+', upper)\n",
    "        sum=0\n",
    "        for x in numberSole:\n",
    "            if \"Textile\" == sole[sole.find(x)+len(x)+1:sole.find(x)+len(x)+7+1]:\n",
    "                sole = sole[sole.find(\"Textile\"):]\n",
    "                MaterialSoleTextile = x\n",
    "            elif \"Rubber\" == sole[sole.find(x)+len(x)+1:sole.find(x)+len(x)+6+1]:\n",
    "                sole = sole[sole.find(\"Rubber\"):]\n",
    "                MaterialSoleRubber = x\n",
    "            elif \"Polyester\" == sole[sole.find(x)+len(x)+1:sole.find(x)+len(x)+9+1]:\n",
    "                sole = sole[sole.find(\"Polyester\"):]\n",
    "                MaterialSoleTextile = x\n",
    "            elif \"ThermoplasticPolyurethane\" == sole[sole.find(x)+len(x)+1:sole.find(x)+len(x)+25+1]:\n",
    "                sole = sole[sole.find(\"ThermoplasticPolyurethane\"):]\n",
    "                MaterialSoleThermoplasticPolyurethane = x\n",
    "            elif \"Leather\" == sole[sole.find(x)+len(x)+1:sole.find(x)+len(x)+7+1]:\n",
    "                sole = sole[sole.find(\"Leather\"):]\n",
    "                MaterialSoleLeather = x\n",
    "            else:\n",
    "                sole = sole[sole.find(x)+len(x)+1:]\n",
    "                sum += int(x)\n",
    "                MaterialSoleOther = x\n",
    "        sum =0\n",
    "        for x in numberUpper:\n",
    "            if \"Textile\" == upper[upper.find(x)+len(x)+1:upper.find(x)+len(x)+7+1]:\n",
    "                upper = upper[upper.find(\"Textile\"):]\n",
    "                MaterialUpperTextile = x\n",
    "            elif \"Rubber\" == upper[upper.find(x)+len(x)+1:upper.find(x)+len(x)+6+1]:\n",
    "                upper = upper[upper.find(\"Rubber\"):]\n",
    "                MaterialUpperRubber = x\n",
    "            elif \"Polyester\" == upper[upper.find(x)+len(x)+1:upper.find(x)+len(x)+9+1]:\n",
    "                upper = upper[upper.find(\"Polyester\"):]\n",
    "                MaterialUpperPolyester = x\n",
    "            elif \"ThermoplasticPolyurethane\" == upper[upper.find(x)+len(x)+1:upper.find(x)+len(x)+25+1]:\n",
    "                upper = upper[upper.find(\"ThermoplasticPolyurethane\"):]\n",
    "                MaterialUpperThermoplasticPolyurethane = x\n",
    "            elif \"Leather\" == upper[upper.find(x)+len(x)+1:upper.find(x)+len(x)+7+1]:\n",
    "                upper = upper[upper.find(\"Leather\"):]\n",
    "                MaterialUpperLeather = x\n",
    "            else:\n",
    "                upper = upper[upper.find(x)+len(x)+1:]\n",
    "                sum += int(x)\n",
    "                MaterialUpperOther = x   \n",
    "    \n",
    "    \n",
    "    for product_key in Productkey_Item:\n",
    "        if(len(product_key.get_text())>=0):\n",
    "            ProductKey = product_key.get_text()[len('Product Code: '):]\n",
    "    description =\"\"\n",
    "    for i in range(len(Details_Item)):\n",
    "        if i<len(Details_Item)-1:\n",
    "            description += Details_Item[i].get_text()+ \" , \"\n",
    "        else:\n",
    "            description += Details_Item[i].get_text()\n",
    "    Data['Details'].append(description)\n",
    "    for brand in Brand_Item:\n",
    "        if Brand_Item != None:\n",
    "            Brand=brand.text\n",
    "    for typ in Type_Item:\n",
    "        Type = typ.get_text()[:typ.get_text().index(\" \")]\n",
    "\n",
    "    #Add to Data\n",
    "    Data['ProductKey'].append(ProductKey)\n",
    "    Data['Price'].append(Price)\n",
    "    Data['Name'].append(Name)\n",
    "    Data['Color'].append(Color)\n",
    "    Data['Brand'].append(Brand)\n",
    "    Data['NumberCatalog'].append(numberCatalog)\n",
    "    Data['Gender'].append(Gender)\n",
    "    Data['Type'].append(Type)\n",
    "    Data['Reviews'].append(Reviews)\n",
    "    Data['GlobalRank'].append(GlobalRank)\n",
    "    Data['RankSize'].append(RankSize)\n",
    "    Data['RankComfort'].append(RankComfort)\n",
    "    Data['RankQuality'].append(RankQuality)\n",
    "    Data['MaterialSoleRubber'].append(MaterialSoleRubber)\n",
    "    Data['MaterialSolePolyester'].append(MaterialSolePolyester)\n",
    "    Data['MaterialSoleTextile'].append(MaterialSoleTextile)\n",
    "    Data['MaterialSoleThermoplasticPolyurethane'].append(MaterialSoleThermoplasticPolyurethane)\n",
    "    Data['MaterialSoleLeather'].append(MaterialSoleLeather)\n",
    "    Data['MaterialSoleOther'].append(MaterialSoleOther)\n",
    "    Data['MaterialUpperRubber'].append(MaterialUpperRubber)\n",
    "    Data['MaterialUpperPolyester'].append(MaterialUpperPolyester)\n",
    "    Data['MaterialUpperTextile'].append(MaterialUpperTextile)\n",
    "    Data['MaterialUpperThermoplasticPolyurethane'].append(MaterialUpperThermoplasticPolyurethane)\n",
    "    Data['MaterialUpperLeather'].append(MaterialUpperLeather)\n",
    "    Data['MaterialUpperOther'].append(MaterialUpperOther)\n",
    "    print(\"Adding Product:\"+ProductKey)\n",
    "    \n",
    "    #----> Get All The Other Page Of Shoes Which is in diffrent Price And color\n",
    "    if IsfirstColor == True:\n",
    "        for url in templink:\n",
    "            if url != None:  #---->The correct link is usally None\n",
    "                respone = requests.get(url, headers=agent , timeout=2)\n",
    "                if respone.status_code == 200:\n",
    "                    ExtractInfo_FromSite(url , respone ,agent, numberCatalog ,Gender, False)\n",
    "    #return True #if there is Other Color ot this type, else return false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eceff725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UpdateData Using Selenium\n",
    "#This Function deal With the Main Menu in www.Asos.com\n",
    "def UpdateData(url,NumberCatalog ,Gender, agent):\n",
    "    try:\n",
    "        #Create Connection to Asos Server\n",
    "        respone = requests.get(url, headers=agent , timeout=2)\n",
    "        if respone.status_code == 200:\n",
    "            print (\"Respone Is ok , The page Exist\")\n",
    "            \n",
    "            LinkListAllProduct = []\n",
    "            isNextPage = True\n",
    "            NumPage = 1\n",
    "            number_Catalog = NumberCatalog\n",
    "            driver = webdriver.Chrome(\"C:\\Program Files (x86)\\Google\\chromedriver.exe\")   #->>>Seleinum\n",
    "            driver.implicitly_wait(10)\n",
    "            driver.get(url)\n",
    "            while isNextPage:\n",
    "                ItemLinkNextPage = driver.find_elements(By.XPATH, \"//section[@data-auto-id=\"+str(NumPage)+\"]//a[@class='productLink_KM4PI']\")\n",
    "                for link in ItemLinkNextPage:\n",
    "                    LinkListAllProduct.append(link.get_attribute('href'))\n",
    "                NextPage = driver.find_elements(By.CSS_SELECTOR,\".loadButton_i3U2b\")\n",
    "                if NextPage:\n",
    "                    NextPage[0].click()#Open other section of products\n",
    "                    NumPage +=1\n",
    "                else:\n",
    "                    isNextPage = False\n",
    "            driver.close()\n",
    "            print(\"Total Product By Gender:\"+str(Gender)+\" \"+str(len(LinkListAllProduct)))\n",
    "            \n",
    "            #---->Extract all the Product\n",
    "            print (\"Start To Extract\")\n",
    "            for link in LinkListAllProduct:\n",
    "                respone = requests.get(link, headers=agent , timeout=2)\n",
    "                if respone.status_code == 200:\n",
    "                    try:\n",
    "                        ExtractInfo_FromSite(link , respone ,agent, number_Catalog ,Gender, True)\n",
    "                        number_Catalog+=1\n",
    "                    except:\n",
    "                        print(\"Extract Not Working\")\n",
    "            return number_Catalog\n",
    "        else:\n",
    "            print (\"Response Code: {0}\".format(respone.status_code))\n",
    "            return number_Catalog\n",
    "    \n",
    "    except Exception as e:\n",
    "            print(\"Somting goes worng\")\n",
    "            print(str(e))\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffc950f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--->Create The DataFrame\n",
    "def CreateDataFrame(Data):\n",
    "    df = pd.DataFrame(Data)\n",
    "    print(df.info())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64fc0f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--->Save The DataFrame in Csv Doc\n",
    "def SaveToCsv(df,path):\n",
    "    if not df.empty:\n",
    "        df.to_csv(path)\n",
    "        print(\"\\n-->Sucssesful Save DataFrame By Crawling\\n\")\n",
    "    else:\n",
    "        print(\"\\n-->Crawling Maybe Not Succses\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7914453c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respone Is ok , The page Exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_16560\\362924880.py:14: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"C:\\Program Files (x86)\\Google\\chromedriver.exe\")   #->>>Seleinum\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somting goes worng\n",
      "Message: no such window: target window already closed\n",
      "from unknown error: web view not found\n",
      "  (Session info: chrome=109.0.5414.120)\n",
      "Stacktrace:\n",
      "Backtrace:\n",
      "\t(No symbol) [0x00F6F243]\n",
      "\t(No symbol) [0x00EF7FD1]\n",
      "\t(No symbol) [0x00DED04D]\n",
      "\t(No symbol) [0x00DD2D7A]\n",
      "\t(No symbol) [0x00E3BE7B]\n",
      "\t(No symbol) [0x00E4C196]\n",
      "\t(No symbol) [0x00E38386]\n",
      "\t(No symbol) [0x00E1163C]\n",
      "\t(No symbol) [0x00E1269D]\n",
      "\tGetHandleVerifier [0x01209A22+2655074]\n",
      "\tGetHandleVerifier [0x011FCA24+2601828]\n",
      "\tGetHandleVerifier [0x01018C0A+619850]\n",
      "\tGetHandleVerifier [0x01017830+614768]\n",
      "\t(No symbol) [0x00F005FC]\n",
      "\t(No symbol) [0x00F05968]\n",
      "\t(No symbol) [0x00F05A55]\n",
      "\t(No symbol) [0x00F1051B]\n",
      "\tBaseThreadInitThunk [0x75FA6BD9+25]\n",
      "\tRtlGetFullPathName_UEx [0x776E8FD2+1218]\n",
      "\tRtlGetFullPathName_UEx [0x776E8F9D+1165]\n",
      "\n",
      "Respone Is ok , The page Exist\n",
      "Somting goes worng\n",
      "Message: target frame detached\n",
      "  (failed to check if window was closed: disconnected: unable to connect to renderer)\n",
      "  (Session info: chrome=109.0.5414.120)\n",
      "Stacktrace:\n",
      "Backtrace:\n",
      "\t(No symbol) [0x00F6F243]\n",
      "\t(No symbol) [0x00EF7FD1]\n",
      "\t(No symbol) [0x00DECF10]\n",
      "\t(No symbol) [0x00DDF9DB]\n",
      "\t(No symbol) [0x00DDE7E8]\n",
      "\t(No symbol) [0x00DDEEF7]\n",
      "\t(No symbol) [0x00DF5F54]\n",
      "\t(No symbol) [0x00DEF82B]\n",
      "\t(No symbol) [0x00DEF350]\n",
      "\t(No symbol) [0x00DEFBA2]\n",
      "\t(No symbol) [0x00DEFE80]\n",
      "\t(No symbol) [0x00E1BD55]\n",
      "\t(No symbol) [0x00E1C22B]\n",
      "\t(No symbol) [0x00E4E64C]\n",
      "\t(No symbol) [0x00E385D4]\n",
      "\t(No symbol) [0x00E4C9EB]\n",
      "\t(No symbol) [0x00E38386]\n",
      "\t(No symbol) [0x00E1163C]\n",
      "\t(No symbol) [0x00E1269D]\n",
      "\tGetHandleVerifier [0x01209A22+2655074]\n",
      "\tGetHandleVerifier [0x011FCA24+2601828]\n",
      "\tGetHandleVerifier [0x01018C0A+619850]\n",
      "\tGetHandleVerifier [0x01017830+614768]\n",
      "\t(No symbol) [0x00F005FC]\n",
      "\t(No symbol) [0x00F05968]\n",
      "\t(No symbol) [0x00F05A55]\n",
      "\t(No symbol) [0x00F1051B]\n",
      "\tBaseThreadInitThunk [0x75FA6BD9+25]\n",
      "\tRtlGetFullPathName_UEx [0x776E8FD2+1218]\n",
      "\tRtlGetFullPathName_UEx [0x776E8F9D+1165]\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Data columns (total 24 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   ProductKey                              0 non-null      float64\n",
      " 1   Name                                    0 non-null      float64\n",
      " 2   NumberCatalog                           0 non-null      float64\n",
      " 3   Gender                                  0 non-null      float64\n",
      " 4   Brand                                   0 non-null      float64\n",
      " 5   Price                                   0 non-null      float64\n",
      " 6   Color                                   0 non-null      float64\n",
      " 7   Details                                 0 non-null      float64\n",
      " 8   Type                                    0 non-null      float64\n",
      " 9   MaterialSoleRubber                      0 non-null      float64\n",
      " 10  MaterialSolePolyester                   0 non-null      float64\n",
      " 11  MaterialSoleTextile                     0 non-null      float64\n",
      " 12  MaterialSoleThermoplasticPolyurethane   0 non-null      float64\n",
      " 13  MaterialSoleOther                       0 non-null      float64\n",
      " 14  MaterialUpperRubber                     0 non-null      float64\n",
      " 15  MaterialUpperPolyester                  0 non-null      float64\n",
      " 16  MaterialUpperTextile                    0 non-null      float64\n",
      " 17  MaterialUpperThermoplasticPolyurethane  0 non-null      float64\n",
      " 18  MaterialUpperOther                      0 non-null      float64\n",
      " 19  GlobalRank                              0 non-null      float64\n",
      " 20  Reviews                                 0 non-null      float64\n",
      " 21  RankSize                                0 non-null      float64\n",
      " 22  RankComfort                             0 non-null      float64\n",
      " 23  RankQuality                             0 non-null      float64\n",
      "dtypes: float64(24)\n",
      "memory usage: 124.0 bytes\n",
      "None\n",
      "\n",
      "-->Crawling Maybe Not Succses\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Data columns (total 24 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   ProductKey                              0 non-null      float64\n",
      " 1   Name                                    0 non-null      float64\n",
      " 2   NumberCatalog                           0 non-null      float64\n",
      " 3   Gender                                  0 non-null      float64\n",
      " 4   Brand                                   0 non-null      float64\n",
      " 5   Price                                   0 non-null      float64\n",
      " 6   Color                                   0 non-null      float64\n",
      " 7   Details                                 0 non-null      float64\n",
      " 8   Type                                    0 non-null      float64\n",
      " 9   MaterialSoleRubber                      0 non-null      float64\n",
      " 10  MaterialSolePolyester                   0 non-null      float64\n",
      " 11  MaterialSoleTextile                     0 non-null      float64\n",
      " 12  MaterialSoleThermoplasticPolyurethane   0 non-null      float64\n",
      " 13  MaterialSoleOther                       0 non-null      float64\n",
      " 14  MaterialUpperRubber                     0 non-null      float64\n",
      " 15  MaterialUpperPolyester                  0 non-null      float64\n",
      " 16  MaterialUpperTextile                    0 non-null      float64\n",
      " 17  MaterialUpperThermoplasticPolyurethane  0 non-null      float64\n",
      " 18  MaterialUpperOther                      0 non-null      float64\n",
      " 19  GlobalRank                              0 non-null      float64\n",
      " 20  Reviews                                 0 non-null      float64\n",
      " 21  RankSize                                0 non-null      float64\n",
      " 22  RankComfort                             0 non-null      float64\n",
      " 23  RankQuality                             0 non-null      float64\n",
      "dtypes: float64(24)\n",
      "memory usage: 124.0 bytes\n"
     ]
    }
   ],
   "source": [
    "#---->#Info for crawling www.asos.com\n",
    "\n",
    "#Dictionry Object - With List Of Data\n",
    "Data = {'ProductKey': [] ,'Name':[] ,'NumberCatalog':[] ,\"Gender\":[] ,'Brand': [] , 'Price' : [] ,'Color' : [] , 'Details': []  , 'Type' : [] , 'MaterialSoleRubber' : [] ,'MaterialSolePolyester' : [], 'MaterialSoleTextile' : [] ,\"MaterialSoleThermoplasticPolyurethane\":[] , \"MaterialSoleOther\": [], 'MaterialUpperRubber' : [] ,'MaterialUpperPolyester' : [], 'MaterialUpperTextile' : [] ,\"MaterialUpperThermoplasticPolyurethane\": [], 'MaterialUpperOther':[] , 'GlobalRank' : [] , \"Reviews\":[] , \"RankSize\":[] ,\"RankComfort\":[],\"RankQuality\":[] }\n",
    "csvPath = \"./CSV_Document/AsosData.csv\"\n",
    "NumberCatalog =1 \n",
    "\n",
    "urlWomen = \"https://www.asos.com/women/shoes/cat/?cid=4172\"               #--->Women url\n",
    "urlMen= \"https://www.asos.com/men/shoes-boots-trainers/cat/?cid=4209\"     #--->Men url\n",
    "agent = {\"User-Agent\":'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36'}\n",
    "\n",
    "number_Catalog = UpdateData(urlWomen ,NumberCatalog, \"Women\", agent)\n",
    "number_Catalog = UpdateData(urlMen , number_Catalog, \"Men\", agent)\n",
    "\n",
    "df = CreateDataFrame(Data)\n",
    "SaveToCsv(df,csvPath)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba661637",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
